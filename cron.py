from core.api import *
import threading
from time import sleep
from utils import DatabaseManager
from config import *
import random
import traceback
from datetime import datetime

def comment_progress(url, post_name, username, delay, token=None, cookie=None, proxy=None):
    try:
        print(f"\n[{datetime.now()}] üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω post: {post_name}")
        db = DatabaseManager(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD, database='user')
        
        # X·ª≠ l√Ω token v√† cookie
        if token:
            print(f"[{datetime.now()}] üîë S·ª≠ d·ª•ng token cho {post_name}")
            fbtk = FacebookToken(token=token, proxy=proxy)
            cookie = fbtk.get_cookie()
            print(f"[{datetime.now()}] üç™ ƒê√£ l·∫•y cookie t·ª´ token cho {post_name}")
        
        try:
            crawler = FacebookCrawler(url, cookie, proxy)
            crawler.getCount()
            comment_count = crawler.comment_count
            reaction_count = crawler.reaction_count
            # Th√™m comment v√†o database
            comments = crawler.getComments()
        except:
            if not token:
                gettoken = FacebookTokenExtractor('EAAAAAY', proxy)
                token = gettoken.get_login(cookie)['access_token']
            
            fbtk = FacebookToken(token=token, proxy=proxy)
            cookie = fbtk.get_cookie()
            print(cookie)
            crawler = FacebookCrawler(url, cookie, proxy)
            comment_count, reaction_count = fbtk.getCount(crawler.owner_id + '_' + crawler.id)
            comments = fbtk.getComments(crawler.owner_id + '_' + crawler.id)


        print(f"[{datetime.now()}] üìä Post {post_name} c√≥ {comment_count} comment v√† {reaction_count} reaction")

        # C·∫≠p nh·∫≠t th√¥ng tin post
        db.bulk_update(
            'posts',
            [{
                'post_name': post_name,
                'reaction_count': crawler.reaction_count,
                'comment_count': crawler.comment_count,
                'last_comment': comments[0]['created_time'] if comments else None
            }],
            'post_name'
        )

        
        if comments:
            comment_data = db.fetch_data('comments')
            existing_comment_ids = {c[0] for c in comment_data}  # Gi·∫£ s·ª≠ comment_id n·∫±m ·ªü v·ªã tr√≠ ƒë·∫ßu ti√™n trong tuple

            # L·ªçc ra c√°c comment ch∆∞a c√≥ trong database
            new_comments = [
                (c['comment_id'], crawler.id, post_name, c['author_id'], c['author_name'], 
                c['author_avatar'], c['content'], '', '', c['created_time'], username)
                for c in comments if c['comment_id'] not in existing_comment_ids
            ]
            db.add_data(
                'comments',
                ['comment_id', 'post_id', 'post_name', 'author_id', 'author_name', 
                 'author_avatar', 'content', 'info', 'phone_number', 'created_time', 'username'],
                new_comments
            )
            print(f"[{datetime.now()}] üíæ ƒê√£ l∆∞u {len(new_comments)} comment m·ªõi cho {post_name}")

        db.close()
        sleep(delay/1000)  # Convert ms to seconds
        print(f"[{datetime.now()}] ‚è≥ Ho√†n th√†nh x·ª≠ l√Ω {post_name}. T·∫°m d·ª´ng {delay}ms")

    except Exception as e:
        print(f"\n[{datetime.now()}] ‚ùå L·ªói khi x·ª≠ l√Ω {post_name}:")
        traceback.print_exc()
        sleep(10)  # Tr√°nh spam l·ªói

def process_post(post_data):
    while True:
        try:
            # L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t m·ªói l·∫ßn l·∫∑p
            post_name = post_data[1]
            url = post_data[2]
            username = post_data[-1]
            delay = post_data[-3]

            db = DatabaseManager(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD, database='user')
            tokens = db.fetch_data('tokens') or []
            cookies = db.fetch_data('cookies') or []
            proxies = db.fetch_data('proxies') or []
            db.close()

            # Random ch·ªçn proxy
            proxy = random.choice(proxies)[0] if proxies else None
            
            # Random ch·ªçn token ho·∫∑c cookie
            auth = None
            if tokens or cookies:
                if tokens and cookies:
                    auth = random.choice(["token", "cookie"])
                else:
                    auth = "token" if tokens else "cookie"
                
                if auth == "token":
                    token = random.choice(tokens)[1]
                    cookie = None
                else:
                    cookie = random.choice(cookies)[1]
                    token = None

            threading.Thread(target=comment_progress, args=(url, post_name, username, delay, token, cookie, proxy)).start()
            sleep(delay/1000)  # Convert ms to seconds

        except Exception as e:
            print(f"\n[{datetime.now()}] ‚ùå L·ªói lu·ªìng x·ª≠ l√Ω {post_data[1]}:")
            traceback.print_exc()
            sleep(5)  # ƒê·ª£i 5s tr∆∞·ªõc khi th·ª≠ l·∫°i

def cookie_progress(cookie, cookie_id, proxy):
    db = DatabaseManager(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD, database='user')
    
    gettoken = FacebookTokenExtractor('EAAAAAY', proxy=proxy)
    try:
        token = gettoken.get_login(cookie)['access_token']
        db.bulk_update(
            'tokens',
            [{'token_id': cookie_id, 'token': token}],
            'token_id'
        )
    except:
        db.bulk_update(
            'cookies',
            [{'cookie_id': cookie_id, 'status': 'die'}],
            'cookie_id'
        )

    db.close()

def progress_cookie():
    db = DatabaseManager(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD, database='user')
    while True:
        threads = []
        proxies = db.fetch_data('proxies') or []
        proxy = random.choice(proxies)[0] if proxies else None

        cookies = db.fetch_data('cookies')
        for ck in cookies:
            cookie = ck[1]
            cookie_id = ck[0]
            t = threading.Thread(target=cookie_progress, args=(cookie, cookie_id, proxy))
            threads.append(t)
            t.start()
        
        for t in threads:
            t.join()

        sleep(300)

def main():
    print(f"[{datetime.now()}] üöÄ Kh·ªüi ƒë·ªông h·ªá th·ªëng...")
    threading.Thread(target=progress_cookie).start()
    while True:
        try:
            # L·∫•y danh s√°ch post m·ªõi m·ªói 30 gi√¢y
            db = DatabaseManager(host=DB_HOST, port=DB_PORT, user=DB_USER, password=DB_PASSWORD, database='user')
            current_posts = {post[1]: post for post in db.fetch_data('posts')}
            db.close()

            # Ki·ªÉm tra v√† t·∫°o lu·ªìng m·ªõi
            active_threads = {t.name: t for t in threading.enumerate() if isinstance(t, threading.Thread)}
            
            for post_name, post in current_posts.items():
                if post_name not in active_threads:
                    print(f"[{datetime.now()}] üßµ T·∫°o lu·ªìng m·ªõi cho: {post_name}")
                    thread = threading.Thread(
                        target=process_post, 
                        args=(post,),
                        name=post_name,
                        daemon=True
                    )
                    thread.start()

            sleep(30)  # C·∫≠p nh·∫≠t danh s√°ch post m·ªói 30 gi√¢y

        except Exception as e:
            print(f"\n[{datetime.now()}] ‚ùå L·ªói ch√≠nh:")
            traceback.print_exc()
            sleep(60)

if __name__ == "__main__":
    main()